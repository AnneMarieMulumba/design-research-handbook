---
layout: page
title:  "Quantifying attitudes"
lang: en
permalink: "/quantifying/"
trans_url: "/fr-needed/"
---
Quantifying attitudes requires...
- Additional rules of evidence, and
- Using established questions, and
- Asking enough people, or
- Being cautious about how you use numbers

# Additional rules of evidence
## The question must be valid.
Your question actually measures what you care about. Answers to your question correlate with other answers or behaviors they should.
## The question must be reliable.
When you ask the same person the same question about the same thing multiple times, you get the same answer.
## The study must have enough power.
You ask enough participants the question to make useful statements about people in general.

# Use established questions
The easiest way to be reliable and valid: 
use previously tested questions!
(“published psychometric scales”)

## System Usability Scale

Brooke, J. (1986). System usability scale (SUS): a quick-and-dirty method of system evaluation user information. Reading, UK: Digital Equipment Co Ltd, 43.

To score the SUS:
1. For odd items: subtract one from the user response.
2. For even-numbered items: subtract the user responses from 5
3. This scales all values from 0 to 4 (with four being the most positive response).
4. Add up the converted responses for each user and multiply that total by 2.5. This converts the range of possible values from 0 to 100 instead of from 0 to 40.

## SUPR-Q

Sauro, J. (2015). SUPR-Q: A comprehensive measure of the quality of the website user experience. Journal of usability studies, 10(2), 68-86.

To score the SUPR-Q: You add up the responses for the first 12 questions and add this to 1/2 the score of the NPS question (I am confident con. The lowest possible score is a 12 and the maximum possible score is a 65. You can then compare your score to industry benchmarks.

## SEQ

https://measuringu.com/seq10/

## NPS

We discourage using net promoter scores. Jared Spool's [description of NPS' problems](
https://articles.uie.com/net-promoter-score-considered-harmful-and-what-ux-professionals-can-do-about-it/

A little more rigorous: https://measuringu.com/nps-harmful/
) shares why. Also see [Jeff Sauro's study of how NPS relates to key experience metrics](https://measuringu.com/nps-harmful/). 


# Asking enough people

## How many people is enough?
No one rule, but depends on:
* Margin of error you need
* Confidence level you need
* How many people you want to make a statement about

Use a [sample size calculator](https://select-statistics.co.uk/calculators/sample-size-calculator-population-proportion/) to determine how many people you need. 

## Yikes! How do I get that many people?
* Automated usability testing
* Cumulative data gathering
* Flow-integrated surveys

## Not enough people? 
* Don’t use an overall score
* Instead:
  * Report each participant’s score
  * Say “participants scored”
  * Don’t use numbers at all


_This content came from a research community presentation. See the [original slides](https://docs.google.com/presentation/d/1jS4qc1HRu2bwkwSZF_N7bODGcJKlJsorFNSODYf0cQk/edit#slide=id.g44c71c1b88_0_165).



